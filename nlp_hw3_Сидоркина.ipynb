{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckoGHoJOB_tM",
        "outputId": "8c79bfbb-74d9-4b50-8abd-7f83e2699a77"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.10/dist-packages (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ba3ZF33ljXG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5afaec0c-e967-4c8a-dcad-151ef7cf483b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from string import punctuation\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install corus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hrdr6Hl78ymO",
        "outputId": "e2199a42-2673-4770-ab7c-7f496f6f1d00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: corus in /usr/local/lib/python3.10/dist-packages (0.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Толкования из файлика"
      ],
      "metadata": {
        "id": "9iq-_V4IjInW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я собрала толкования из МАС и записала их в json с ключами `word` для слова и `meanings` для списка значений."
      ],
      "metadata": {
        "id": "j-DDSZK1pS1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za-BDoWXCOZZ",
        "outputId": "9e8af8ea-9ab9-4610-8eb0-74f61e5c2fd6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m_path = 'hw3_meanings.json'"
      ],
      "metadata": {
        "id": "tSXLdZqcpni6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "glfYEfwfqA0c",
        "outputId": "14a05238-c9e5-4957-82a3-3710a1415550"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join('/content/drive/MyDrive/', m_path),\n",
        "          'r', encoding=\"utf-8\") as f:\n",
        "  data = json.load(f)\n",
        "  print(data[0]['word'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5pWll5PpBmL",
        "outputId": "a34d8b54-4f4f-4d25-f92e-504a63dac38e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "крона\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = dict()\n",
        "for k in data:\n",
        "    words[k['word']] = {'meanings':k['meanings'], 'texts':[]}"
      ],
      "metadata": {
        "id": "JfcR5-sp9rsS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(*words.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW_pukH49KCQ",
        "outputId": "4bedc542-1f93-49a9-c337-b4019a63bd2e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "крона крошка час голова таз\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Контексты"
      ],
      "metadata": {
        "id": "mmGrcO5djPDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Буду использовать корпуса с готовой разметкой, т.к. ручной лемматизатор грузился сто часов.\n",
        "\n",
        "### НКРЯ"
      ],
      "metadata": {
        "id": "mUXEBLc9hRDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/dialogue-evaluation/morphoRuEval-2017/raw/master/RNC_texts.rar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce8-55CVdBVk",
        "outputId": "ef848576-6157-4a74-a675-e60237d3233d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-06 23:17:40--  https://github.com/dialogue-evaluation/morphoRuEval-2017/raw/master/RNC_texts.rar\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dialogue-evaluation/morphoRuEval-2017/master/RNC_texts.rar [following]\n",
            "--2023-12-06 23:17:40--  https://raw.githubusercontent.com/dialogue-evaluation/morphoRuEval-2017/master/RNC_texts.rar\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5775644 (5.5M) [application/octet-stream]\n",
            "Saving to: ‘RNC_texts.rar’\n",
            "\n",
            "RNC_texts.rar       100%[===================>]   5.51M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-12-06 23:17:40 (69.4 MB/s) - ‘RNC_texts.rar’ saved [5775644/5775644]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x RNC_texts.rar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjtKsdYvd42W",
        "outputId": "c1346ef7-6d01-4b1d-ec04-c6c184184145"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from RNC_texts.rar\n",
            "\n",
            "\n",
            "Would you like to replace the existing file RNCgoldInUD_Morpho.conll\n",
            "75436890 bytes, modified on 2017-03-02 16:16\n",
            "with a new one\n",
            "75436890 bytes, modified on 2017-03-02 16:16\n",
            "\n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit N\n",
            "\n",
            "No files to extract\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm RNC_texts.rar"
      ],
      "metadata": {
        "id": "yNjs4k9ad-1K"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from corus import load_morphoru_rnc\n",
        "\n",
        "path = 'RNCgoldInUD_Morpho.conll'\n",
        "records = load_morphoru_rnc(path)"
      ],
      "metadata": {
        "id": "4kp_idB33hvV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(records).tokens[0].lemma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "abftHjVqXSim",
        "outputId": "61cd45e7-de04-4483-fd82-a351046c6588"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'кстати'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in records:\n",
        "    for word in sent.tokens:\n",
        "        if word.lemma in words.keys():\n",
        "            words[word.lemma]['texts'].append(sent.tokens)"
      ],
      "metadata": {
        "id": "qGmPw_wG4xMp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ГИКРЯ"
      ],
      "metadata": {
        "id": "zFCtWG5-iOgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/dialogue-evaluation/morphoRuEval-2017/raw/master/GIKRYA_texts_new.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8LQPfcQhv56",
        "outputId": "c62091de-2077-44cd-b6aa-3c1eb4428db4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-06 23:21:38--  https://github.com/dialogue-evaluation/morphoRuEval-2017/raw/master/GIKRYA_texts_new.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dialogue-evaluation/morphoRuEval-2017/master/GIKRYA_texts_new.zip [following]\n",
            "--2023-12-06 23:21:38--  https://raw.githubusercontent.com/dialogue-evaluation/morphoRuEval-2017/master/GIKRYA_texts_new.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8961678 (8.5M) [application/zip]\n",
            "Saving to: ‘GIKRYA_texts_new.zip’\n",
            "\n",
            "GIKRYA_texts_new.zi 100%[===================>]   8.55M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2023-12-06 23:21:39 (99.8 MB/s) - ‘GIKRYA_texts_new.zip’ saved [8961678/8961678]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip GIKRYA_texts_new.zip\n",
        "!rm GIKRYA_texts_new.zip"
      ],
      "metadata": {
        "id": "WaMYESb5ial3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff3b3800-b11e-4ae1-a7c9-48e36b7acc6d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  GIKRYA_texts_new.zip\n",
            "replace gikrya_new_test.out? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace gikrya_new_train.out? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from corus import load_morphoru_gicrya\n",
        "\n",
        "path = 'gikrya_new_test.out'\n",
        "records = load_morphoru_gicrya(path)"
      ],
      "metadata": {
        "id": "Xyup0AxxieH4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit\n",
        "\n",
        "for sent in records:\n",
        "    for word in sent.tokens:\n",
        "        if word.lemma in words.keys():\n",
        "            words[word.lemma]['texts'].append(sent.tokens)"
      ],
      "metadata": {
        "id": "GnYm06AMiijG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# проверяем для всего ли есть тексты\n",
        "\n",
        "for w in words.keys():\n",
        "  print(len(words[w]['texts']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izSc8v5ni7hD",
        "outputId": "3189c23d-85a3-4024-d19f-54833c21e8f3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "10\n",
            "554\n",
            "805\n",
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in words['крона']['texts']:\n",
        "    text = [x.text for x in k]\n",
        "    print(' '.join(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZxvGQFwi9jL",
        "outputId": "d7a95f66-902b-4553-9383-6b66621fc5c2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Они выше самых высоких каштанов , светло-зелёными холмами высятся их кроны над лесом .\n",
            "В этом месте я сделал жест , указав на крону одного из камфорных деревьев , под которыми мы проходили .\n",
            "На нас пахнуло холодом , зашелестели , зашептали густые листья в кронах деревьев .\n",
            "Изредка солнечный свет пробивался сквозь кроны деревьев длинными тонкими пальцами , и тогда схваченные этими пальцами капли дождя сверкали , как хрустальные стёклышки .\n",
            "Он развернул Андрея к окну , и тот увидел кроны деревьев , бешено проносящиеся мимо стекла слева направо .\n",
            "Первыми забили тревогу питерское \" Единство \" и нижегородская \" Крона \", которые , перебиваясь с воды на хлеб , с миру по нитке искали средства для поездки на очередной тур первенства .\n",
            "Специально для национальных героев Центр репродукции установил льготный тариф -- 500 словацких крон вместо обычных 1750 .\n",
            "Шишки пихты кавказской , подобно свечкам , украшают осенью самый верх кроны ; их никто не видел лежащими на земле , поскольку шишки у пихты рассыпаются на отдельные чешуйки ещё на дереве .\n",
            "Дело в том , что зацвести и дать плоды он может только при полном солнечном освещении , для чего ему нужно \" подняться \" над кроной дерева .\n",
            "А вот многоножка южная -- настоящий эпифит , поскольку преимущественно растёт на замшелых стволах деревьев ; её крупноперистые листья можно видеть высоко над землёй в кронах больших деревьев .\n",
            "Падение капсулы повалило несколько деревьев , образовав брешь в кронах , сквозь которую на поверхность бурлящего болота , покрытого обманчивым ковром плавающего мха , падали косые солнечные лучи .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Классификация контекстов"
      ],
      "metadata": {
        "id": "3ylYxvDwjT82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/lopuhin/python-adagram.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqnnCVIIlToo",
        "outputId": "8cd4d4f5-a435-4bac-8596-3abdbea4a170"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/lopuhin/python-adagram.git\n",
            "  Cloning https://github.com/lopuhin/python-adagram.git to /tmp/pip-req-build-tqnfushx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lopuhin/python-adagram.git /tmp/pip-req-build-tqnfushx\n",
            "  Resolved https://github.com/lopuhin/python-adagram.git to commit cf3639f10d6a1efbcb602f45a1da89ef55ce5794\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from adagram==0.0.1) (3.0.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from adagram==0.0.1) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.10/dist-packages (from adagram==0.0.1) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from adagram==0.0.1) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import adagram\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0FlfnLy5laye"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сначала причешем контексты\n",
        "\n",
        "for w in words.keys():\n",
        "     words[w]['texts'] = [list(map(lambda x: x.lemma, k)) for k in words[w]['texts']]"
      ],
      "metadata": {
        "id": "rmtL6YH1jA24"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(*words['крона']['texts'][0])"
      ],
      "metadata": {
        "id": "GVws9duMkEWm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fec0df0e-b4fb-41c8-c84b-d0b6555801aa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "они высокий самый высокий каштан , светло-зеленый холм выситься их крона над лес .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl \"https://s3.amazonaws.com/kostia.lopuhin/all.a010.p10.d300.w5.m100.nonorm.slim.joblib\" > all.a010.p10.d300.w5.m100.nonorm.s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBJrX-QOkt_s",
        "outputId": "7e4cff2d-fd00-4fcf-9b16-5762d83285fa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1394M  100 1394M    0     0  53.0M      0  0:00:26  0:00:26 --:--:-- 41.9M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vm = adagram.VectorModel.load('all.a010.p10.d300.w5.m100.nonorm.s')"
      ],
      "metadata": {
        "id": "EXXCmEmIlKcF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vm.word_sense_probs('голова')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3frrnyIlQaA",
        "outputId": "90ecd347-f58e-46c7-a374-836e5e6ad8e4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0.15136618792493253),\n",
              " (2, 0.18463972125993772),\n",
              " (3, 0.23746755179898937),\n",
              " (4, 0.031868947553770864),\n",
              " (5, 0.18276442527655343),\n",
              " (6, 0.21124967139097275)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words.keys():\n",
        "    words[w]['adas'] = []\n",
        "    for text in words[w]['texts']:\n",
        "        means = vm.disambiguate(w, text)\n",
        "        words[w]['adas'].append(np.argmax(means))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tebWAQPTlv6I",
        "outputId": "8965b4d4-7f9b-4f24-de43-1f6da124d40e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/adagram/model.py:171: RuntimeWarning: divide by zero encountered in log\n",
            "  z = np.log(z)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words['крошка']['adas']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeEacAvVn1yh",
        "outputId": "2a33d073-fa4f-4f1c-d8ff-35abf7fd7b9d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 1, 0, 0, 0, 2, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install simple-elmo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzJ6d3Ndy67p",
        "outputId": "53984ad1-e7b9-4c4c-8f54-62378de0f1c6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: simple-elmo in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from simple-elmo) (3.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from simple-elmo) (1.23.5)\n",
            "Requirement already satisfied: smart-open>1.8.1 in /usr/local/lib/python3.10/dist-packages (from simple-elmo) (6.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from simple-elmo) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from simple-elmo) (1.11.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->simple-elmo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->simple-elmo) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->simple-elmo) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://vectors.nlpl.eu/repository/20/196.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sax0BmyC0cEc",
        "outputId": "1905d29d-bdaa-4893-f3f7-4c9b46003036"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-06 23:22:56--  http://vectors.nlpl.eu/repository/20/196.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.181\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.181|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206986351 (197M) [application/zip]\n",
            "Saving to: ‘196.zip.1’\n",
            "\n",
            "196.zip.1           100%[===================>] 197.40M  23.0MB/s    in 9.3s    \n",
            "\n",
            "2023-12-06 23:23:06 (21.1 MB/s) - ‘196.zip.1’ saved [206986351/206986351]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from simple_elmo import ElmoModel\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "\n",
        "model = ElmoModel()\n",
        "model.load(\"196.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "XpDVOp-O0eym",
        "outputId": "bd21fa6e-39d6-4d4b-918f-d3c621b806cc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/simple_elmo/model.py:531: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  lstm_cell = tf.compat.v1.nn.rnn_cell.LSTMCell(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The model is now loaded.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_elmo_vectors(word, tokens, model):\n",
        "    all_vectors = model.get_elmo_vectors(tokens)\n",
        "    word_vecs = []\n",
        "    for i in range(len(tokens)):\n",
        "        try:\n",
        "            word_vecs.append(all_vectors[i][tokens[i].index(word)])\n",
        "        except ValueError:  # если нормализация накосячила и лемму не найти\n",
        "            continue\n",
        "    return word_vecs"
      ],
      "metadata": {
        "id": "pM52YnRD0y3R"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words.keys():\n",
        "    big_vecs = model.get_elmo_vectors(words[w]['texts'])\n",
        "    vecs = []\n",
        "    for i in range(len(words[w]['texts'])):\n",
        "        vec = big_vecs[i][words[w]['texts'][i].index(w)]\n",
        "        vecs.append(vec)\n",
        "\n",
        "    vect = AffinityPropagation(random_state=0).fit(np.stack(vecs))\n",
        "    words[w]['elmo'] = list(vect.labels_)"
      ],
      "metadata": {
        "id": "7k-58apN5SUH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words['крона']['elmo']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qStSPfm73qA",
        "outputId": "5c6c6c31-dcf8-4205-d200-5077f9db1fdf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[2, 3, 3, 3, 3, 0, 1, 2, 3, 3, 2]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Кластеризация словарных толкований"
      ],
      "metadata": {
        "id": "nQRzzKSIYliN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from string import punctuation\n",
        "import nltk\n",
        "from itertools import chain"
      ],
      "metadata": {
        "id": "k7FK9ZWKe6N9"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#токенизатор из старой домашки + лемматизация\n",
        "\n",
        "def clean_up(pp: str):\n",
        "    morph = MorphAnalyzer()\n",
        "    sent = sent_tokenize(pp.lower())\n",
        "    tok = list(map(lambda x: word_tokenize(x), sent))\n",
        "    tok = list(chain(*tok))\n",
        "    depunct = list(filter(lambda x: x not in punctuation, tok))\n",
        "    depunct = list(filter(lambda x: x not in '«»–', depunct))\n",
        "    lem = list(map(lambda x: morph.parse(x)[0].normal_form, depunct))\n",
        "\n",
        "    return lem"
      ],
      "metadata": {
        "id": "d0jDpowZeZOJ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words.keys():\n",
        "    words[w]['adas_mas'] = []\n",
        "    for text in words[w]['meanings']:\n",
        "        means = vm.disambiguate(w, clean_up(text))\n",
        "        words[w]['adas_mas'].append(np.argmax(means))"
      ],
      "metadata": {
        "id": "77veFD_qCebi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b968ac9-2a5e-4094-a24f-2af795b94441"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/adagram/model.py:171: RuntimeWarning: divide by zero encountered in log\n",
            "  z = np.log(z)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words['голова']['adas_mas']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNSmKUDzeGgo",
        "outputId": "795c4bb2-6e99-4754-aaa0-1a866785c340"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 3, 4, 4, 5, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words.keys():\n",
        "    padded = [[w]+clean_up(x) for x in words[w]['meanings']]\n",
        "    big_vecs = model.get_elmo_vectors(padded)\n",
        "    vecs = []\n",
        "    for i in range(len(words[w]['meanings'])):\n",
        "        vec = big_vecs[i][padded[i].index(w)]\n",
        "        vecs.append(vec)\n",
        "\n",
        "    vect = AffinityPropagation(random_state=0).fit(np.stack(vecs))\n",
        "    words[w]['elmo_mas'] = list(vect.labels_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC6HZfXgdi67",
        "outputId": "113e66e7-615c-407b-8f56-85b8f4c645e1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_affinity_propagation.py:53: UserWarning: All samples have mutually equal similarities. Returning arbitrary cluster center(s).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_affinity_propagation.py:53: UserWarning: All samples have mutually equal similarities. Returning arbitrary cluster center(s).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words['голова']['elmo_mas']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLN-ZRfGfs50",
        "outputId": "2a22d1f3-8a98-45a2-cf3c-cc92fe0cafed"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0, 0, 0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Разметка"
      ],
      "metadata": {
        "id": "ts33sYXfosPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#вот так я размечала\n",
        "\n",
        "for w in words.keys():\n",
        "    for j in range(5, 10):\n",
        "        print(words[w]['elmo_mas'])\n",
        "        print(words[w]['adas_mas'])\n",
        "        print(*words[w]['texts'][j])\n",
        "        print(words[w]['elmo'][j])\n",
        "        print(words[w]['adas'][j])\n",
        "        break\n",
        "\n",
        "words['крона']['rank_elma'] = [0, 1, 0, 0, 0]\n",
        "words['крона']['rank_adas'] = [1, 1, 1, 1, 1]\n",
        "words['крошка']['rank_elma'] = [0, 0, 0, 0, 0]\n",
        "words['крошка']['rank_adas'] = [1, 1, 0, 0, 1]\n",
        "words['час']['rank_elma'] = [1, 0, 0, 1, 0]\n",
        "words['час']['rank_adas'] = [1, 0, 1, 0, 0]\n",
        "words['голова']['rank_elma'] = [0, 0, 0, 0, 0]\n",
        "words['голова']['rank_adas'] = [1, 1, 0, 0, 0]\n",
        "words['таз']['rank_elma'] = [0, 1, 0, 0, 0]\n",
        "words['таз']['rank_adas'] = [1, 0, 0, 1, 1]"
      ],
      "metadata": {
        "id": "j9GLLLYigVLu",
        "outputId": "61cc4039-1220-4485-a267-125e522efdd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1]\n",
            "[0, 1]\n",
            "первый забить тревога питерский \" единство \" и нижегородский \" крона \", который , перебиваться с вода на хлеб , с мир по нитка искать средство для поездка на очередной тур первенство .\n",
            "0\n",
            "2\n",
            "[0, 0, 1, 1]\n",
            "[0, 0, 1, 0]\n",
            "горячий солнечный свет падать на скатерть , покрыть липкий пятно и крошка , и Андрей вдруг подумать , что для миллион луч это настоящий трагедия -- начать свой путь на поверхность солнце , пронестись сквозь бесконечный пустота космос , пробить многокилометровый небо -- и всё только для то , чтобы угаснуть на отвратительный останки вчерашний суп .\n",
            "1\n",
            "0\n",
            "[0, 1, 1, 1, 1, 1]\n",
            "[4, 4, 4, 5, 4, 0]\n",
            "два смена в детский сад подряд -- это 16 час .\n",
            "0\n",
            "4\n",
            "[1, 0, 0, 0, 0, 1]\n",
            "[5, 3, 4, 4, 5, 5]\n",
            "я казаться , что кто надо , кто понимать , кто правильно расставлять приоритет , тот не прийти это даже в голова .\n",
            "26\n",
            "3\n",
            "[0, 1]\n",
            "[1, 0]\n",
            "к то же снижать риск воспаление орган таз .\n",
            "3\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Accuracy and comparison"
      ],
      "metadata": {
        "id": "ybXSz9O6oxft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elma = []\n",
        "adas = []\n",
        "for w in words.keys():\n",
        "    elma.extend(words[w]['rank_elma'])\n",
        "    adas.extend(words[w]['rank_adas'])\n",
        "\n",
        "print('Accuracy for ElmoModel {}%'.format(100 * sum(elma)/ len(elma)))\n",
        "print('Accuracy for AdaGram {}%'.format(100 * sum(adas)/ len(adas)))"
      ],
      "metadata": {
        "id": "lDOJrmFahn4z",
        "outputId": "c02021e2-8d44-4cea-f966-7d45b35f2a58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for ElmoModel 16.0%\n",
            "Accuracy for AdaGram 60.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`AdaGram` справляется сильно лучше, чем `ElmoModel`. Почему?\n",
        "\n",
        "`AdaGram` считает вероятности появления определённого значения и у него есть внутренний порог для адекватного количества смыслов на слово. Для `ElmoModel` я просто кластеризовала контекстные вектора вручную. Хотя значения есть употребление, ближайший контекст всё-таки не полностью идентичен значению. СКлёрновский классификатор просто разделял очень непохожие контексты на очень разные значения, поэтому WSD с `ElmoModel` находил в текстах по 60+ разных значения, когда в словаре было только 6. Например:"
      ],
      "metadata": {
        "id": "rJfmis51u46H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Значение в тексте {}'.format(words['голова']['elmo'][7]))\n",
        "print('Значения в словаре {}'.format(words['голова']['elmo_mas']))\n",
        "print(*words['голова']['texts'][7])"
      ],
      "metadata": {
        "id": "eBj3yKI7s--I",
        "outputId": "0cc7853b-d56d-4b8a-ba2b-63be58214daa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Значение в тексте 71\n",
            "Значения в словаре [1, 0, 0, 0, 0, 1]\n",
            "леонид броневой сыграть мюллер , это — первый роль , принести в то время сорокапятилетний актер известность ( кстати , вот еще анекдот : « штирлиц выстрелить мюллер в голова , но она отлететь от он .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "REsdln-xw7lI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}